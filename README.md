# Montecarlo_Reinforcement_Learning
This project is about an implementation of the well-known algorithm in the Reinforcement Learning anvironment Montecarlo. 
For this project we'll use an adaptative policy so we will start with a 100% of probabilities of making a random movement to increase the exploration of the maze and while the training is running, we'll decrease 
this probability to the 50% so we can improve the optimal path while we have explored enough.

The best path I could find on my own is 40 steps(maybe I misscounted :D) but with training the best I could reach is 43. I encourage you to try to beat this record!

Feel free to make any changes in the code so it is adapted to your necessities, like changing the policy, the total episodes, the decreasing of the epsilon... It's all on your hands.

You can find the video where I try this algorithm in 

See you soon!
